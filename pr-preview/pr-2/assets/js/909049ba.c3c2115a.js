"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[627],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>g});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=a.createContext({}),s=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=s(e.components);return a.createElement(c.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,c=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=s(n),m=r,g=d["".concat(c,".").concat(m)]||d[m]||u[m]||i;return n?a.createElement(g,o(o({ref:t},p),{},{components:n})):a.createElement(g,o({ref:t},p))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=m;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[d]="string"==typeof e?e:r,o[1]=l;for(var s=2;s<i;s++)o[s]=n[s];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},9136:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>c,default:()=>g,frontMatter:()=>l,metadata:()=>s,toc:()=>d});var a=n(7462),r=n(3366),i=(n(7294),n(3905)),o=["components"],l={title:"Iceberg table",id:"iceberg"},c="Apache Iceberg",s={unversionedId:"docs/configuration/materializations/iceberg",id:"docs/configuration/materializations/iceberg",title:"Iceberg table",description:"Athena supports read, time travel, write, and DDL queries for Apache Iceberg tables that use the Apache Parquet format for data and the AWS Glue catalog for their metastore.",source:"@site/docs/docs/configuration/materializations/iceberg.md",sourceDirName:"docs/configuration/materializations",slug:"/docs/configuration/materializations/iceberg",permalink:"/pr-preview/pr-2/docs/configuration/materializations/iceberg",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/current/docs/docs/configuration/materializations/iceberg.md",tags:[],version:"current",lastUpdatedAt:1682813982,formattedLastUpdatedAt:"Apr 30, 2023",frontMatter:{title:"Iceberg table",id:"iceberg"},sidebar:"docs",previous:{title:"Highly-available Hive table",permalink:"/pr-preview/pr-2/docs/configuration/materializations/hive-ha"},next:{title:"Seeds",permalink:"/pr-preview/pr-2/docs/configuration/seeds"}},p={},d=[{value:"Getting started",id:"getting-started",level:2},{value:"Incremental tables",id:"incremental-tables",level:2}],u={toc:d},m="wrapper";function g(e){var t=e.components,n=(0,r.Z)(e,o);return(0,i.kt)(m,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"apache-iceberg"},"Apache Iceberg"),(0,i.kt)("p",null,"Athena supports read, time travel, write, and DDL queries for Apache Iceberg tables that use the Apache Parquet format for data and the AWS Glue catalog for their metastore."),(0,i.kt)("p",null,"Apache Iceberg is an open table format for very large analytic datasets. Iceberg manages large collections of files as tables, and it supports modern analytical data lake operations such as record-level insert, update, delete, and time travel queries. The Iceberg specification allows seamless table evolution such as schema and partition evolution and is designed for optimized usage on Amazon S3. Iceberg also helps guarantee data correctness under concurrent write scenarios."),(0,i.kt)("p",null,"The dbt-athena adapter supports table materialization for Apache Iceberg."),(0,i.kt)("h2",{id:"getting-started"},"Getting started"),(0,i.kt)("p",null,"To get started, add the following config block to your model:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{\n  config(\n    materialized='table',\n    table_type='iceberg',\n    format='parquet',\n    partitioned_by=['bucket(user_id, 5)'],\n    table_properties={\n      'optimize_rewrite_delete_file_threshold': '2'\n    }\n  )\n}}\n\nSELECT\n    'A' AS user_id,\n    'pi' AS name,\n    'active' AS status,\n    17.89 AS cost,\n    1 AS quantity,\n    100000000 AS quantity_big,\n    current_date AS my_date\n")),(0,i.kt)("p",null,"Iceberg supports ",(0,i.kt)("strong",{parentName:"p"},"bucketing")," as hidden partitions, therefore use the ",(0,i.kt)("inlineCode",{parentName:"p"},"partitioned_by")," config to add specific bucketing conditions."),(0,i.kt)("p",null,"Iceberg supports several ",(0,i.kt)("strong",{parentName:"p"},"table formats")," for data : ",(0,i.kt)("inlineCode",{parentName:"p"},"PARQUET"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"AVRO")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"ORC"),"."),(0,i.kt)("h2",{id:"incremental-tables"},"Incremental tables"),(0,i.kt)("p",null,"It is possible to use iceberg in an incremental materialization. Two strategies are supported:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"append"),": new records are appended to the table, this can lead to duplicates"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"merge"),": must be used in combination with ",(0,i.kt)("inlineCode",{parentName:"li"},"unique_key"),".\nIt performs an upsert: new records are added, and records that already existed, are updated. If\n",(0,i.kt)("inlineCode",{parentName:"li"},"delete_condition")," is provided in the model config, it can also delete records based on the\nprovided condition (SQL condition). You can use any column of the incremental table (",(0,i.kt)("inlineCode",{parentName:"li"},"src"),") or\nthe final table (",(0,i.kt)("inlineCode",{parentName:"li"},"target"),"). You must prefix the column by the name of the table to prevent\n",(0,i.kt)("inlineCode",{parentName:"li"},"Column is ambiguous")," error.")),(0,i.kt)("admonition",{type:"caution"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("inlineCode",{parentName:"p"},"MERGE INTO")," is transactional and is supported only for Apache Iceberg tables in ",(0,i.kt)("strong",{parentName:"p"},"Athena engine version 3"),".")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{\n  config(\n    materialized='incremental',\n    table_type='iceberg',\n    incremental_strategy='merge',\n    unique_key='user_id',\n    delete_condition=\"src.status != 'active' and target.my_date < now() - interval '2' year\"\n    format='parquet',\n  )\n}}\n\nSELECT\n    'A' AS user_id,\n    'pi' AS name,\n    'active' AS status,\n    17.89 AS cost,\n    1 AS quantity,\n    100000000 AS quantity_big,\n    current_date AS my_date\n")))}g.isMDXComponent=!0}}]);