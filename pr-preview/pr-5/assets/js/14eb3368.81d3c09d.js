(self.webpackChunk=self.webpackChunk||[]).push([[817],{2015:(e,t,a)=>{var n={"./docs/configuration/materializations/hive-ha.md":4372,"./docs/configuration/materializations/hive.md":9481,"./docs/configuration/materializations/iceberg.md":9136,"./docs/configuration/seeds.md":3836,"./docs/configuration/snapshots.md":9081,"./docs/configuration/table-configuration.md":835,"./docs/contributing/contributing.md":9482,"./docs/contributing/local-development.md":9697,"./docs/getting-started/installation.md":9641,"./docs/getting-started/prerequisites/aws-resources.md":4047,"./docs/getting-started/prerequisites/iam-permissions.md":4632,"./docs/introduction.md":2057,"./docs/known-issues.md":7526,"./faqs/Athena/dbt-threads.md":9252,"./faqs/Athena/too-many-open-partitions.md":9109};function i(e){var t=r(e);return a(t)}function r(e){if(!a.o(n,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return n[e]}i.keys=function(){return Object.keys(n)},i.resolve=r,e.exports=i,i.id=2015},2691:(e,t,a)=>{"use strict";a.d(t,{Z:()=>h});var n=a(7294),i=a(6010),r=a(9960),o=a(3791),s=a(3919),l=a(5999);const d={cardContainer:"cardContainer_S8oU",cardTitle:"cardTitle_HoSo",cardDescription:"cardDescription_c27F",glossaryCard:"glossaryCard_nmCw"};function p(e){var t=e.href,a=e.children;return n.createElement(r.Z,{href:t,className:(0,i.Z)("card padding--lg",d.cardContainer,t.includes("/terms/")&&d.glossaryCard)},a)}function c(e){var t=e.href,a=e.icon,r=e.title,o=e.description,s=e.hoverSnippet;return n.createElement(p,{href:t},n.createElement("h2",{className:(0,i.Z)(!t.includes("/terms/")&&"text--truncate",d.cardTitle),title:r},a," ",r),o&&n.createElement("p",{className:(0,i.Z)(!t.includes("/terms/")&&"text--truncate",d.cardDescription),title:s||o},s||o))}function m(e){var t=e.item,a=(0,o.Wl)(t);return a?n.createElement(c,{href:a,icon:"\ud83d\uddc3\ufe0f",title:t.label,description:(0,l.I)({message:"{count} items",id:"theme.docs.DocCard.categoryDescription",description:"The default description for a category card in the generated index about how many items this category includes"},{count:t.items.length})}):null}function u(e){var t,i,r=e.item,l=(0,s.Z)(r.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",d=(0,o.xz)(null!=(t=r.docId)?t:void 0);if(r.docId&&r.href&&r.href.includes("/terms/")){var p=a(2015)("./"+r.docId+".md");p&&(i=p.frontMatter.hoverSnippet)}return n.createElement(c,{href:r.href,icon:l,title:r.label,description:null==d?void 0:d.description,hoverSnippet:i})}function h(e){var t=e.item;switch(t.type){case"link":return n.createElement(u,{item:t});case"category":return n.createElement(m,{item:t});default:throw new Error("unknown item type "+JSON.stringify(t))}}},4372:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Highly-available Hive table",id:"hive-ha"},l=void 0,d={unversionedId:"docs/configuration/materializations/hive-ha",id:"docs/configuration/materializations/hive-ha",title:"Highly-available Hive table",description:"The current implementation of the Hive table materialization can lead to downtime, because the target table is dropped and re-created. To have a less destructive behavior, it's possible to use the table='tablehiveha' materialization.",source:"@site/docs/docs/configuration/materializations/hive-ha.md",sourceDirName:"docs/configuration/materializations",slug:"/docs/configuration/materializations/hive-ha",permalink:"/pr-preview/pr-5/docs/configuration/materializations/hive-ha",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/configuration/materializations/hive-ha.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Highly-available Hive table",id:"hive-ha"},sidebar:"docs",previous:{title:"Hive table",permalink:"/pr-preview/pr-5/docs/configuration/materializations/hive"},next:{title:"Iceberg table",permalink:"/pr-preview/pr-5/docs/configuration/materializations/iceberg"}},p={},c=[{value:"Known issues",id:"known-issues",level:4}],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"The current implementation of the Hive table materialization can lead to downtime, because the target table is dropped and re-created. To have a less destructive behavior, it's possible to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"table='table_hive_ha'")," materialization."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"table_hive_ha"))," leverages the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/glue/latest/webapi/API_GetTableVersions.html"},"table versions"),' feature of Glue catalog: creating a "tmp" table and swapping the target table to the location of the tmp table.'),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"This materialization is only available for ",(0,r.kt)("inlineCode",{parentName:"p"},"table_type=hive")," (default) and requires using unique locations on S3.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"{{\n  config(\n    materialized='table_hive_ha',\n    format='parquet',\n    partitioned_by=['status'],\n    s3_data_naming='table_unique'\n  )\n}}\n\nselect\n    'a' as user_id,\n    'pi' as user_name,\n    'active' as status\nunion all\nselect\n    'b' as user_id,\n    'sh' as user_name,\n    'active' as status\nunion all\nselect\n    'c' as user_id,\n    'sh' as user_name,\n    'disabled' as status\n")),(0,r.kt)("p",null,"By default, the materialization keeps the last 4 table versions. You can change it by setting ",(0,r.kt)("inlineCode",{parentName:"p"},"versions_to_keep")," on the model configuration."),(0,r.kt)("h4",{id:"known-issues"},"Known issues"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"When swapping from a table with partitions to a table without (and the other way around), there could be a little downtime. In case high performance is needed, consider bucketing instead of partitions"),(0,r.kt)("li",{parentName:"ul"},'By default, Glue "duplicate" the versions internally, so the last 2 versions of a table point to the same location. Therefore it\'s recommended to use ',(0,r.kt)("inlineCode",{parentName:"li"},"versions_to_keep")," >= 4, as this will avoid to have the older location removed.")))}h.isMDXComponent=!0},9481:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Hive table",id:"hive"},l=void 0,d={unversionedId:"docs/configuration/materializations/hive",id:"docs/configuration/materializations/hive",title:"Hive table",description:"The default dbt table materialization will be using a Hive table in Athena.",source:"@site/docs/docs/configuration/materializations/hive.md",sourceDirName:"docs/configuration/materializations",slug:"/docs/configuration/materializations/hive",permalink:"/pr-preview/pr-5/docs/configuration/materializations/hive",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/configuration/materializations/hive.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Hive table",id:"hive"},sidebar:"docs",previous:{title:"Table configuration",permalink:"/pr-preview/pr-5/docs/configuration/table-configuration"},next:{title:"Highly-available Hive table",permalink:"/pr-preview/pr-5/docs/configuration/materializations/hive-ha"}},p={},c=[],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"The default dbt ",(0,r.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/materializations#table"},"table materialization")," will be using a Hive table in Athena.\nWhen used, dbt will run a ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/athena/latest/ug/create-table-as.html"},(0,r.kt)("inlineCode",{parentName:"a"},"CREATE TABLE AS"))," query against Athena."))}h.isMDXComponent=!0},9136:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Iceberg table",id:"iceberg"},l="Apache Iceberg",d={unversionedId:"docs/configuration/materializations/iceberg",id:"docs/configuration/materializations/iceberg",title:"Iceberg table",description:"Athena supports read, time travel, write, and DDL queries for Apache Iceberg tables that use the Apache Parquet format for data and the AWS Glue catalog for their metastore.",source:"@site/docs/docs/configuration/materializations/iceberg.md",sourceDirName:"docs/configuration/materializations",slug:"/docs/configuration/materializations/iceberg",permalink:"/pr-preview/pr-5/docs/configuration/materializations/iceberg",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/configuration/materializations/iceberg.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Iceberg table",id:"iceberg"},sidebar:"docs",previous:{title:"Highly-available Hive table",permalink:"/pr-preview/pr-5/docs/configuration/materializations/hive-ha"},next:{title:"Seeds",permalink:"/pr-preview/pr-5/docs/configuration/seeds"}},p={},c=[{value:"Getting started",id:"getting-started",level:2},{value:"Incremental tables",id:"incremental-tables",level:2}],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"apache-iceberg"},"Apache Iceberg"),(0,r.kt)("p",null,"Athena supports read, time travel, write, and DDL queries for Apache Iceberg tables that use the Apache Parquet format for data and the AWS Glue catalog for their metastore."),(0,r.kt)("p",null,"Apache Iceberg is an open table format for very large analytic datasets. Iceberg manages large collections of files as tables, and it supports modern analytical data lake operations such as record-level insert, update, delete, and time travel queries. The Iceberg specification allows seamless table evolution such as schema and partition evolution and is designed for optimized usage on Amazon S3. Iceberg also helps guarantee data correctness under concurrent write scenarios."),(0,r.kt)("p",null,"The dbt-athena adapter supports table materialization for Apache Iceberg."),(0,r.kt)("h2",{id:"getting-started"},"Getting started"),(0,r.kt)("p",null,"To get started, add the following config block to your model:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"{{\n  config(\n    materialized='table',\n    table_type='iceberg',\n    format='parquet',\n    partitioned_by=['bucket(user_id, 5)'],\n    table_properties={\n      'optimize_rewrite_delete_file_threshold': '2'\n    }\n  )\n}}\n\nSELECT\n    'A' AS user_id,\n    'pi' AS name,\n    'active' AS status,\n    17.89 AS cost,\n    1 AS quantity,\n    100000000 AS quantity_big,\n    current_date AS my_date\n")),(0,r.kt)("p",null,"Iceberg supports ",(0,r.kt)("strong",{parentName:"p"},"bucketing")," as hidden partitions, therefore use the ",(0,r.kt)("inlineCode",{parentName:"p"},"partitioned_by")," config to add specific bucketing conditions."),(0,r.kt)("p",null,"Iceberg supports several ",(0,r.kt)("strong",{parentName:"p"},"table formats")," for data : ",(0,r.kt)("inlineCode",{parentName:"p"},"PARQUET"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"AVRO")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"ORC"),"."),(0,r.kt)("h2",{id:"incremental-tables"},"Incremental tables"),(0,r.kt)("p",null,"It is possible to use iceberg in an incremental materialization. Two strategies are supported:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"append"),": new records are appended to the table, this can lead to duplicates"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"merge"),": must be used in combination with ",(0,r.kt)("inlineCode",{parentName:"li"},"unique_key"),".\nIt performs an upsert: new records are added, and records that already existed, are updated. If\n",(0,r.kt)("inlineCode",{parentName:"li"},"delete_condition")," is provided in the model config, it can also delete records based on the\nprovided condition (SQL condition). You can use any column of the incremental table (",(0,r.kt)("inlineCode",{parentName:"li"},"src"),") or\nthe final table (",(0,r.kt)("inlineCode",{parentName:"li"},"target"),"). You must prefix the column by the name of the table to prevent\n",(0,r.kt)("inlineCode",{parentName:"li"},"Column is ambiguous")," error.")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("inlineCode",{parentName:"p"},"MERGE INTO")," is transactional and is supported only for Apache Iceberg tables in ",(0,r.kt)("strong",{parentName:"p"},"Athena engine version 3"),".")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"{{\n  config(\n    materialized='incremental',\n    table_type='iceberg',\n    incremental_strategy='merge',\n    unique_key='user_id',\n    delete_condition=\"src.status != 'active' and target.my_date < now() - interval '2' year\"\n    format='parquet',\n  )\n}}\n\nSELECT\n    'A' AS user_id,\n    'pi' AS name,\n    'active' AS status,\n    17.89 AS cost,\n    1 AS quantity,\n    100000000 AS quantity_big,\n    current_date AS my_date\n")))}h.isMDXComponent=!0},3836:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Seeds",id:"seeds"},l=void 0,d={unversionedId:"docs/configuration/seeds",id:"docs/configuration/seeds",title:"Seeds",description:"Seeds are CSV files in your dbt project (typically in your seeds directory), that dbt can load into your data warehouse using the dbt seed command. Read more about seeds in the dbt docs.",source:"@site/docs/docs/configuration/seeds.md",sourceDirName:"docs/configuration",slug:"/docs/configuration/seeds",permalink:"/pr-preview/pr-5/docs/configuration/seeds",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/configuration/seeds.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Seeds",id:"seeds"},sidebar:"docs",previous:{title:"Iceberg table",permalink:"/pr-preview/pr-5/docs/configuration/materializations/iceberg"},next:{title:"Snapshots",permalink:"/pr-preview/pr-5/docs/configuration/snapshots"}},p={},c=[],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Seeds are CSV files in your dbt project (typically in your seeds directory), that dbt can load into your data warehouse using the ",(0,r.kt)("inlineCode",{parentName:"p"},"dbt seed")," command. Read more about seeds in the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/seeds"},"dbt docs"),"."))}h.isMDXComponent=!0},9081:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>p,default:()=>b,frontMatter:()=>d,metadata:()=>c,toc:()=>u});var n,i=a(7462),r=a(3366),o=(a(7294),a(3905)),s=a(5108),l=["components"],d={title:"Snapshots",id:"snapshots"},p=void 0,c={unversionedId:"docs/configuration/snapshots",id:"docs/configuration/snapshots",title:"Snapshots",description:"The dbt-athena adapter supports dbt snapshots. Both the dbt timestamp and check strategy are supported. To create a snapshot, create a snapshot file in the dbt snapshots directory. If directory does not exist create one. Read more about dbt snapshots here.",source:"@site/docs/docs/configuration/snapshots.md",sourceDirName:"docs/configuration",slug:"/docs/configuration/snapshots",permalink:"/pr-preview/pr-5/docs/configuration/snapshots",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/configuration/snapshots.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Snapshots",id:"snapshots"},sidebar:"docs",previous:{title:"Seeds",permalink:"/pr-preview/pr-5/docs/configuration/seeds"},next:{title:"Known issues",permalink:"/pr-preview/pr-5/docs/known-issues"}},m={},u=[{value:"Detecting row changes",id:"detecting-row-changes",level:2},{value:"Timestamp strategy (recommended)",id:"timestamp-strategy-recommended",level:3},{value:"Check strategy",id:"check-strategy",level:3},{value:"Hard-deletes (opt-in)",id:"hard-deletes-opt-in",level:3},{value:"Example",id:"example",level:2}],h=(n="File",function(e){return s.warn("Component "+n+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)}),g={toc:u},k="wrapper";function b(e){var t=e.components,a=(0,r.Z)(e,l);return(0,o.kt)(k,(0,i.Z)({},g,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"The dbt-athena adapter supports ",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/snapshots"},"dbt snapshots"),". Both the dbt timestamp and check strategy are supported. To create a snapshot, create a snapshot file in the dbt snapshots directory. If directory does not exist create one. Read more about dbt snapshots ",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/snapshots"},"here"),"."),(0,o.kt)("h2",{id:"detecting-row-changes"},"Detecting row changes"),(0,o.kt)("h3",{id:"timestamp-strategy-recommended"},"Timestamp strategy (recommended)"),(0,o.kt)("p",null,"To use the timestamp strategy refer to the ",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/snapshots#timestamp-strategy-recommended"},"dbt docs")),(0,o.kt)("h3",{id:"check-strategy"},"Check strategy"),(0,o.kt)("p",null,"To use the check strategy refer to the ",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/snapshots#check-strategy"},"dbt docs")),(0,o.kt)("h3",{id:"hard-deletes-opt-in"},"Hard-deletes (opt-in)"),(0,o.kt)("p",null,"The materialization also supports invalidating hard deletes. Check the ",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/snapshots#hard-deletes-opt-in"},"docs")," to understand the usage."),(0,o.kt)("h2",{id:"example"},"Example"),(0,o.kt)(h,{name:"seeds/employment_indicators_november_2022_csv_tables.csv",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-csv"},"Series_reference,Period,Data_value,Suppressed\nMEIM.S1WA,1999.04,80267,\nMEIM.S1WA,1999.05,70803,\nMEIM.S1WA,1999.06,65792,\nMEIM.S1WA,1999.07,66194,\nMEIM.S1WA,1999.08,67259,\nMEIM.S1WA,1999.09,69691,\nMEIM.S1WA,1999.1,72475,\nMEIM.S1WA,1999.11,79263,\nMEIM.S1WA,1999.12,86540,\nMEIM.S1WA,2000.01,82552,\nMEIM.S1WA,2000.02,81709,\nMEIM.S1WA,2000.03,84126,\nMEIM.S1WA,2000.04,77089,\nMEIM.S1WA,2000.05,73811,\nMEIM.S1WA,2000.06,70070,\nMEIM.S1WA,2000.07,69873,\nMEIM.S1WA,2000.08,71468,\nMEIM.S1WA,2000.09,72462,\nMEIM.S1WA,2000.1,74897,\n"))),(0,o.kt)(h,{name:"models/example_model.sql",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"{{\n  config(materialized='table')\n}}\n\nselect\n    row_number() over () as id,\n    *,\n    cast(from_unixtime(to_unixtime(now())) as timestamp(6)) AS refresh_timestamp\nfrom {{ ref('employment_indicators_november_2022_csv_tables') }}\n"))),(0,o.kt)(h,{name:"snapshots/model_snapshot_timestamp_strategy.sql",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"{% snapshot model_snapshot_timestamp_strategy %}\n  {{\n      config(\n        strategy='timestamp',\n        updated_at='refresh_timestamp',\n        unique_key='id'\n      )\n  }}\n\n  select * from {{ ref('model') }}\n{% endsnapshot %}\n\n"))),(0,o.kt)(h,{name:"snapshots/model_snapshot_timestamp_strategy_hard_deletes.sql",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"{% snapshot model_snapshot_timestamp_strategy_hard_deletes %}\n  {{\n      config(\n        unique_key='id',\n        strategy='timestamp',\n        updated_at='refresh_timestamp',\n        invalidate_hard_deletes=True,\n      )\n  }}\n  select * from {{ ref('model') }}\n{% endsnapshot %}\n"))),(0,o.kt)(h,{name:"snapshots/model_snapshot_check_strategy.sql",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"{% snapshot model_snapshot_check_strategy %}\n  {{\n      config(\n        unique_key='id',\n        strategy='check',\n        check_cols=['series_reference','data_value']\n      )\n  }}\n  select * from {{ ref('model') }}\n{% endsnapshot %}\n"))),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"Snapshots do not support dropping columns from the source table. If you drop a column, make sure to drop the column from the snapshot as well. Another workaround is to ",(0,o.kt)("inlineCode",{parentName:"p"},"NULL")," the column in the snapshot definition to preserve history")))}b.isMDXComponent=!0},835:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Table configuration",id:"table-configuration"},l=void 0,d={unversionedId:"docs/configuration/table-configuration",id:"docs/configuration/table-configuration",title:"Table configuration",description:"Model configuration",source:"@site/docs/docs/configuration/table-configuration.md",sourceDirName:"docs/configuration",slug:"/docs/configuration/table-configuration",permalink:"/pr-preview/pr-5/docs/configuration/table-configuration",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/configuration/table-configuration.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Table configuration",id:"table-configuration"},sidebar:"docs",previous:{title:"Installation",permalink:"/pr-preview/pr-5/docs/getting-started/installation"},next:{title:"Hive table",permalink:"/pr-preview/pr-5/docs/configuration/materializations/hive"}},p={},c=[{value:"Model configuration",id:"model-configuration",level:2},{value:"Table data location",id:"table-data-location",level:2},{value:"Incremental table models",id:"incremental-table-models",level:2},{value:"On schema change",id:"on-schema-change",level:3}],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"model-configuration"},"Model configuration"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Property"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Default"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"materialized")),(0,r.kt)("td",{parentName:"tr",align:null},"A table materialization like ",(0,r.kt)("inlineCode",{parentName:"td"},"table"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"incremental"),", ",(0,r.kt)("a",{parentName:"td",href:"docs/configuration/materializations/hive-ha"},(0,r.kt)("inlineCode",{parentName:"a"},"table_hive_ha"))),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"s3_data_naming")),(0,r.kt)("td",{parentName:"tr",align:null},"An optional naming policy for the data on S3. See ",(0,r.kt)("a",{parentName:"td",href:"#table-data-location"},"Table data location"),"."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"schema_table_unique"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"external_location")),(0,r.kt)("td",{parentName:"tr",align:null},"If set, the full S3 path in which the table will be saved. (Does not work with Iceberg table)."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"partitioned_by")),(0,r.kt)("td",{parentName:"tr",align:null},"An array list of columns by which the table will be partitioned. \u26a0\ufe0f ",(0,r.kt)("a",{parentName:"td",href:"https://docs.aws.amazon.com/athena/latest/ug/ctas-considerations-limitations.html#ctas-considerations-limitations-partition-and-bucket-limits"},"Limited to the creation of 100 partitions"),"."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"bucketed_by")),(0,r.kt)("td",{parentName:"tr",align:null},"An array list of columns to bucket the data. This is ignored when using Iceberg. Example: ",(0,r.kt)("inlineCode",{parentName:"td"},"[org_id]")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"bucket_count")),(0,r.kt)("td",{parentName:"tr",align:null},"The number of buckets for bucketing your data. This is ignored when using Iceberg. Example: ",(0,r.kt)("inlineCode",{parentName:"td"},"1"),"."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"table_type")),(0,r.kt)("td",{parentName:"tr",align:null},"The type of table in Athena. Supports ",(0,r.kt)("inlineCode",{parentName:"td"},"hive")," or ",(0,r.kt)("inlineCode",{parentName:"td"},"iceberg")," values."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"hive"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"format")),(0,r.kt)("td",{parentName:"tr",align:null},"The data format for the table. Supports ",(0,r.kt)("inlineCode",{parentName:"td"},"ORC"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"PARQUET"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"AVRO"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"JSON"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"TEXTFILE"),"."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"PARQUET"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"write_compression")),(0,r.kt)("td",{parentName:"tr",align:null},"The compression type to use for any storage format that allows compression to be specified. To see which options are available, see ",(0,r.kt)("a",{parentName:"td",href:"https://docs.aws.amazon.com/athena/latest/ug/create-table-as.html"},"CREATE TABLE AS"),". Example: ",(0,r.kt)("inlineCode",{parentName:"td"},"SNAPPY"),"."),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"field_delimiter")),(0,r.kt)("td",{parentName:"tr",align:null},"Custom field delimiter. Used when the format is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"TEXTFILE"),". See ",(0,r.kt)("a",{parentName:"td",href:"https://docs.aws.amazon.com/athena/latest/ug/create-table-as.html"},"CREATE TABLE AS"),". Example: ",(0,r.kt)("inlineCode",{parentName:"td"},"','")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"table_properties")),(0,r.kt)("td",{parentName:"tr",align:null},"Additional table properties to add to the table. Valid for Iceberg only. Example: ",(0,r.kt)("inlineCode",{parentName:"td"},"{'optimize_rewrite_delete_file_threshold': '2'}")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"lf_tags")),(0,r.kt)("td",{parentName:"tr",align:null},"Lake Formation tags for metadata access control, to associate to the table. Example: ",(0,r.kt)("inlineCode",{parentName:"td"},'{"tag1":{"tag1": "value1", "tag2": "value2"}')),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"lf_tags_columns")),(0,r.kt)("td",{parentName:"tr",align:null},"Lake Formation tags for metadata access control, to associate to columns. Example: ",(0,r.kt)("inlineCode",{parentName:"td"},'{"tag1": {"value1": ["column1": "column2"]}}')),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"none"))))),(0,r.kt)("h2",{id:"table-data-location"},"Table data location"),(0,r.kt)("p",null,"The S3 location in which table data is saved, is determined by:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"If ",(0,r.kt)("inlineCode",{parentName:"li"},"external_location")," is defined, that value is used."),(0,r.kt)("li",{parentName:"ol"},"If ",(0,r.kt)("inlineCode",{parentName:"li"},"s3_data_dir")," is defined, the path is determined by this value and ",(0,r.kt)("inlineCode",{parentName:"li"},"s3_data_naming"),"."),(0,r.kt)("li",{parentName:"ol"},"If no ",(0,r.kt)("inlineCode",{parentName:"li"},"s3_data_dir")," is defined, the data is stored under ",(0,r.kt)("inlineCode",{parentName:"li"},"s3_staging_dir/tables/"),".")),(0,r.kt)("p",null,"The options for ",(0,r.kt)("inlineCode",{parentName:"p"},"s3_data_naming")," are:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"uuid")),": ",(0,r.kt)("inlineCode",{parentName:"li"},"{s3_data_dir}/{uuid4()}/")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"table_table")),": ",(0,r.kt)("inlineCode",{parentName:"li"},"{s3_data_dir}/{table}/")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"table_unique")),": ",(0,r.kt)("inlineCode",{parentName:"li"},"{s3_data_dir}/{table}/{uuid4()}/")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"schema_table")),": ",(0,r.kt)("inlineCode",{parentName:"li"},"{s3_data_dir}/{schema}/{table}/")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"schema_table_unique")),": ",(0,r.kt)("inlineCode",{parentName:"li"},"{s3_data_dir}/{schema}/{table}/{uuid4()}/"))),(0,r.kt)("p",null,"It's possible to set the ",(0,r.kt)("inlineCode",{parentName:"p"},"s3_data_naming")," globally in the ",(0,r.kt)("inlineCode",{parentName:"p"},"profile.yml"),", set it for a group of models in the ",(0,r.kt)("inlineCode",{parentName:"p"},"dbt_project.yml")," or overwrite the value for a specific model in the config block."),(0,r.kt)("admonition",{title:"Workgroup with default output location",type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"When using an Athena workgroup with a default output location configured, ",(0,r.kt)("inlineCode",{parentName:"p"},"s3_data_naming")," and any configured buckets are ignored and the location configured in the workgroup is used.")),(0,r.kt)("h2",{id:"incremental-table-models"},"Incremental table models"),(0,r.kt)("p",null,"dbt-athena supports ",(0,r.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/incremental-models"},"incremental models"),". These strategies are supported:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"insert_overwrite")," (default): The insert overwrite strategy deletes the overlapping partitions from the destination table, and then inserts the new records from the source. This strategy depends on the ",(0,r.kt)("inlineCode",{parentName:"li"},"partitioned_by")," keyword! If no partitions are defined, dbt will fall back to the ",(0,r.kt)("inlineCode",{parentName:"li"},"append")," strategy."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"append"),": Insert new records without updating, deleting or overwriting any existing data. There might be duplicate data (e.g. great for log or historical data)."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"merge"),": Conditionally updates, deletes, or inserts rows into an Iceberg table. Used in combination with ",(0,r.kt)("inlineCode",{parentName:"li"},"unique_key"),". \u26a0\ufe0f Only available when using ",(0,r.kt)("a",{parentName:"li",href:"docs/configuration/materializations/iceberg"},"Iceberg"),".")),(0,r.kt)("h3",{id:"on-schema-change"},"On schema change"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"on_schema_change")," is an option to reflect changes of schema in incremental models.\nThe following options are supported:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"ignore")," (default)"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"fail")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"append_new_columns")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"sync_all_columns"))),(0,r.kt)("p",null,"In detail, please refer to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/incremental-models#what-if-the-columns-of-my-incremental-model-change"},"dbt docs"),"."))}h.isMDXComponent=!0},9482:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>p,default:()=>b,frontMatter:()=>d,metadata:()=>c,toc:()=>u});var n,i=a(7462),r=a(3366),o=(a(7294),a(3905)),s=a(5108),l=["components"],d={title:"Become a contributor",sidebar_label:"Contributing",id:"contributing"},p=void 0,c={unversionedId:"docs/contributing/contributing",id:"docs/contributing/contributing",title:"Become a contributor",description:"A community-owned project",source:"@site/docs/docs/contributing/contributing.md",sourceDirName:"docs/contributing",slug:"/docs/contributing/",permalink:"/pr-preview/pr-5/docs/contributing/",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/contributing/contributing.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Become a contributor",sidebar_label:"Contributing",id:"contributing"},sidebar:"docs",previous:{title:"Known issues",permalink:"/pr-preview/pr-5/docs/known-issues"},next:{title:"Local development",permalink:"/pr-preview/pr-5/docs/contributing/local-development"}},m={},u=[{value:"A community-owned project",id:"a-community-owned-project",level:2}],h=(n="Card",function(e){return s.warn("Component "+n+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)}),g={toc:u},k="wrapper";function b(e){var t=e.components,a=(0,r.Z)(e,l);return(0,o.kt)(k,(0,i.Z)({},g,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"a-community-owned-project"},"A community-owned project"),(0,o.kt)("p",null,"The dbt-athena adapter is a community-owned adapter on Github, which means that the code is maintained and developed by a group of individuals rather than a single company or organization. This approach of community ownership ensures that the adapter is not dependent on a single entity, reducing the risk of the code becoming unsupported or abandoned."),(0,o.kt)("p",null,"Community ownership also fosters collaboration, encourages transparency, and helps to ensure that the code is developed and maintained with the needs of the community in mind. The dbt-athena adapter is an excellent example of how the power of the open-source community can be harnessed to develop high-quality, reliable, and sustainable software."),(0,o.kt)("p",null,"Community ownership also means that there is no single point of failure in terms of the code's development and maintenance. With multiple contributors and maintainers, the risk of the project being abandoned or becoming unsupported due to changes in the ownership structure is reduced. Additionally, the diverse perspectives and expertise of the community can result in a more robust and feature-rich codebase."),(0,o.kt)("div",{className:"grid--2-col"},(0,o.kt)(h,{title:"Local development setup",body:"Learn how to setup and debug the project locally",link:"docs/contributing/local-development",icon:"computer",mdxType:"Card"}),(0,o.kt)(h,{title:"Online community building",body:"Getting involved in the dbt Community Slack (#db-athena) is one of the best entry points for contributing. Share your knowledge about Athena and dbt-athena and learn from others.",link:"https://www.getdbt.com/community/join-the-community/",icon:"slack",mdxType:"Card"})))}b.isMDXComponent=!0},9697:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>p,default:()=>b,frontMatter:()=>d,metadata:()=>c,toc:()=>u});var n,i=a(7462),r=a(3366),o=(a(7294),a(3905)),s=a(5108),l=["components"],d={title:"Local development",id:"local-development"},p=void 0,c={unversionedId:"docs/contributing/local-development",id:"docs/contributing/local-development",title:"Local development",description:"Using virtual environments",source:"@site/docs/docs/contributing/local-development.md",sourceDirName:"docs/contributing",slug:"/docs/contributing/local-development",permalink:"/pr-preview/pr-5/docs/contributing/local-development",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/contributing/local-development.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Local development",id:"local-development"},sidebar:"docs",previous:{title:"Contributing",permalink:"/pr-preview/pr-5/docs/contributing/"},next:{title:"Frequently asked questions",permalink:"/pr-preview/pr-5/docs/faqs"}},m={},u=[{value:"Using virtual environments",id:"using-virtual-environments",level:2},{value:"Install a specific package of dbt-athena in your project",id:"install-a-specific-package-of-dbt-athena-in-your-project",level:2},{value:"Local package",id:"local-package",level:3},{value:"Git branch",id:"git-branch",level:3},{value:"Unit tests",id:"unit-tests",level:2}],h=(n="File",function(e){return s.warn("Component "+n+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)}),g={toc:u},k="wrapper";function b(e){var t=e.components,a=(0,r.Z)(e,l);return(0,o.kt)(k,(0,i.Z)({},g,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"using-virtual-environments"},"Using virtual environments"),(0,o.kt)("p",null,"Virtualenv is the most common and easy to install tool for virtual environments. It\u2019s a great tool for beginners."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-terminal"},"python3 -m venv dbt-env             # create the environment\nsource dbt-env/bin/activate         # activate the environment for Mac and Linux\ndbt-env\\Scripts\\activate            # activate the environment for Windows\n")),(0,o.kt)("p",null,"If you install dbt in a virtual environment, you need to reactivate that same virtual environment each time you create a shell window or session."),(0,o.kt)("h2",{id:"install-a-specific-package-of-dbt-athena-in-your-project"},"Install a specific package of dbt-athena in your project"),(0,o.kt)("h3",{id:"local-package"},"Local package"),(0,o.kt)("p",null,"When you are experiencing a bug, it's often very useful to run against a local version of dbt-athena, with the ability to add debug logs and fixes."),(0,o.kt)(h,{name:"requirements.txt",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"-e /Users/username/Code/dbt-athena\n"))),(0,o.kt)("p",null,"Then, run ",(0,o.kt)("inlineCode",{parentName:"p"},"pip install -r requirements.txt")),(0,o.kt)("h3",{id:"git-branch"},"Git branch"),(0,o.kt)("p",null,"To test a specific branch in your project, add the following to your ",(0,o.kt)("inlineCode",{parentName:"p"},"requirements.txt")," file:"),(0,o.kt)(h,{name:"requirements.txt",mdxType:"File"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"git+https://github.com/dbt-athena/dbt-athena.git@main#dbt-athena-community\n"))),(0,o.kt)("p",null,"Then, run ",(0,o.kt)("inlineCode",{parentName:"p"},"pip install -r requirements.txt")),(0,o.kt)("h2",{id:"unit-tests"},"Unit tests"),(0,o.kt)("p",null,"To run the unit tests using Pytest in dbt-athena, follow these instructions:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-terminal"},"make install_deps\nmake unit_test\n")))}b.isMDXComponent=!0},9641:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Installing dbt-athena",id:"installation",sidebar_label:"Installation"},l=void 0,d={unversionedId:"docs/getting-started/installation",id:"docs/getting-started/installation",title:"Installing dbt-athena",description:"Prerequisites",source:"@site/docs/docs/getting-started/installation.md",sourceDirName:"docs/getting-started",slug:"/docs/getting-started/installation",permalink:"/pr-preview/pr-5/docs/getting-started/installation",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/getting-started/installation.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Installing dbt-athena",id:"installation",sidebar_label:"Installation"},sidebar:"docs",previous:{title:"IAM permissions",permalink:"/pr-preview/pr-5/docs/getting-started/prerequisites/iam-permissions"},next:{title:"Table configuration",permalink:"/pr-preview/pr-5/docs/configuration/table-configuration"}},p={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install dbt-athena",id:"install-dbt-athena",level:2},{value:"Configuring dbt-athena",id:"configuring-dbt-athena",level:3}],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Installed dbt Core using the ",(0,r.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/core/installation"},"installation instructions")," for your operating system + a dbt project initialized."),(0,r.kt)("li",{parentName:"ul"},"A working Athena setup.")),(0,r.kt)("h2",{id:"install-dbt-athena"},"Install dbt-athena"),(0,r.kt)("p",null,"Pip is the easiest way to install the ",(0,r.kt)("a",{parentName:"p",href:"https://pypi.org/project/dbt-athena-community/"},"dbt-athena-community package")," in your dbt project:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-terminal"},"pip install dbt-athena-community\n")),(0,r.kt)("h3",{id:"configuring-dbt-athena"},"Configuring dbt-athena"),(0,r.kt)("p",null,"A dbt profile can be configured in the ",(0,r.kt)("inlineCode",{parentName:"p"},"profiles.yml")," to run against AWS Athena using the following configuration:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Option"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Required?"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"s3_staging_dir")),(0,r.kt)("td",{parentName:"tr",align:null},"S3 location to store Athena query results and metadata"),(0,r.kt)("td",{parentName:"tr",align:null},"Required"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"s3://bucket/dbt/"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"s3_data_dir")),(0,r.kt)("td",{parentName:"tr",align:null},"Prefix for storing tables, if different from the connection's ",(0,r.kt)("inlineCode",{parentName:"td"},"s3_staging_dir")),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"s3://bucket2/dbt/"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"s3_data_naming")),(0,r.kt)("td",{parentName:"tr",align:null},"How to generate table paths in ",(0,r.kt)("inlineCode",{parentName:"td"},"s3_data_dir"),". Default: ",(0,r.kt)("inlineCode",{parentName:"td"},"schema_table_unique"),". See ",(0,r.kt)("a",{parentName:"td",href:"docs/configuration/table-configuration"},"Table Configuration")),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"schema_table_unique"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"region_name")),(0,r.kt)("td",{parentName:"tr",align:null},"AWS region of your Athena instance"),(0,r.kt)("td",{parentName:"tr",align:null},"Required"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"eu-central-1"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"schema")),(0,r.kt)("td",{parentName:"tr",align:null},"Specify the schema (Athena database) to build models into (lowercase ",(0,r.kt)("strong",{parentName:"td"},"only"),")"),(0,r.kt)("td",{parentName:"tr",align:null},"Required"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"dbt"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"database")),(0,r.kt)("td",{parentName:"tr",align:null},"Specify the database (Data catalog) to build models into (lowercase ",(0,r.kt)("strong",{parentName:"td"},"only"),")"),(0,r.kt)("td",{parentName:"tr",align:null},"Required"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"awsdatacatalog"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"poll_interval")),(0,r.kt)("td",{parentName:"tr",align:null},"Interval in seconds to use for polling the status of query results in Athena. Default: ",(0,r.kt)("inlineCode",{parentName:"td"},"1")),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"5"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"aws_profile_name")),(0,r.kt)("td",{parentName:"tr",align:null},"Profile to use from your AWS shared credentials file."),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"my-profile"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"aws_access_key_id")),(0,r.kt)("td",{parentName:"tr",align:null},"AWS access key to sign AWS API requests. This is optional, as ",(0,r.kt)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"},"credentials are determined automatically based on the aws cli and boto3 conventions")," and stored login info."),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"AKIAIOSFODNN7EXAMPLE"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"aws_secret_access_key")),(0,r.kt)("td",{parentName:"tr",align:null},"AWS secret access key to sign AWS API requests. This is optional, as ",(0,r.kt)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"},"credentials are determined automatically based on the aws cli and boto3 conventions")," and stored login info."),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"work_group")),(0,r.kt)("td",{parentName:"tr",align:null},"Identifier of Athena workgroup"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"my-custom-workgroup"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"num_retries")),(0,r.kt)("td",{parentName:"tr",align:null},"Number of times to retry a failing query. Default: ",(0,r.kt)("inlineCode",{parentName:"td"},"5")),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"3"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"lf_tags")),(0,r.kt)("td",{parentName:"tr",align:null},"LF tags to apply to any database created by dbt"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},'{"origin": "dbt", "team": "analytics"}'))))),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Example profiles.yml entry:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"athena:\n  target: dev\n  outputs:\n    dev:\n      type: athena\n      work_group: primary\n      s3_staging_dir: s3://aws-athena-query-results/dbt/\n      s3_data_dir: s3://your_s3_bucket/dbt/\n      s3_data_naming: schema_table_unique\n      region_name: eu-central-1\n      database: awsdatacatalog\n      schema: dbt\n      aws_profile_name: my-profile\n      lf_tags:\n        origin: dbt\n        team: analytics\n      threads: 8\n")),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Additional information")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"threads")," is supported"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"database")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"catalog")," can be used interchangeably")))}h.isMDXComponent=!0},4047:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"AWS resources",id:"aws-resources"},l=void 0,d={unversionedId:"docs/getting-started/prerequisites/aws-resources",id:"docs/getting-started/prerequisites/aws-resources",title:"AWS resources",description:"To get started, you will need an S3 bucket, for instance my-bucket, and an Athena database:",source:"@site/docs/docs/getting-started/prerequisites/aws-resources.md",sourceDirName:"docs/getting-started/prerequisites",slug:"/docs/getting-started/prerequisites/aws-resources",permalink:"/pr-preview/pr-5/docs/getting-started/prerequisites/aws-resources",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/getting-started/prerequisites/aws-resources.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"AWS resources",id:"aws-resources"},sidebar:"docs",previous:{title:"Introduction",permalink:"/pr-preview/pr-5/"},next:{title:"IAM permissions",permalink:"/pr-preview/pr-5/docs/getting-started/prerequisites/iam-permissions"}},p={},c=[],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"To get started, you will need an S3 bucket, for instance ",(0,r.kt)("inlineCode",{parentName:"p"},"my-bucket"),", and an Athena database:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE DATABASE IF NOT EXISTS analytics_dev\nCOMMENT 'Analytics models generated by dbt (development)'\nLOCATION 's3://my-bucket/'\nWITH DBPROPERTIES ('creator'='Foo Bar', 'email'='foo@bar.com');\n")),(0,r.kt)("p",null,"If the database does not exist, then dbt will attempt to create it automatically."),(0,r.kt)("admonition",{title:"AWS Glue",type:"info"},(0,r.kt)("p",{parentName:"admonition"},"You can also use ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/athena/latest/ug/glue-athena.html"},"AWS Glue")," to create and manage your Athena databases.")))}h.isMDXComponent=!0},4632:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"IAM permissions",id:"iam-permissions"},l=void 0,d={unversionedId:"docs/getting-started/prerequisites/iam-permissions",id:"docs/getting-started/prerequisites/iam-permissions",title:"IAM permissions",description:"Athena IAM permissions",source:"@site/docs/docs/getting-started/prerequisites/iam-permissions.md",sourceDirName:"docs/getting-started/prerequisites",slug:"/docs/getting-started/prerequisites/iam-permissions",permalink:"/pr-preview/pr-5/docs/getting-started/prerequisites/iam-permissions",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/getting-started/prerequisites/iam-permissions.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"IAM permissions",id:"iam-permissions"},sidebar:"docs",previous:{title:"AWS resources",permalink:"/pr-preview/pr-5/docs/getting-started/prerequisites/aws-resources"},next:{title:"Installation",permalink:"/pr-preview/pr-5/docs/getting-started/installation"}},p={},c=[{value:"Athena IAM permissions",id:"athena-iam-permissions",level:2},{value:"Glue IAM permissions",id:"glue-iam-permissions",level:2},{value:"S3 IAM permissions",id:"s3-iam-permissions",level:2},{value:"Lake Formation",id:"lake-formation",level:2}],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"athena-iam-permissions"},"Athena IAM permissions"),(0,r.kt)("p",null,"Athena permissions that are required to run queries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"athena:StartQueryExecution",\n"athena:GetQueryResults",\n"athena:GetWorkGroup",\n"athena:StopQueryExecution",\n"athena:GetQueryExecution",\n')),(0,r.kt)("h2",{id:"glue-iam-permissions"},"Glue IAM permissions"),(0,r.kt)("p",null,"dbt-athena uses the AWS Glue API to fetch metadata. You will need to set these permissions on the Glue databases you are reading from:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"glue:GetDatabase",\n"glue:GetDatabases",\n"glue:GetTable",\n"glue:GetTables",\n"glue:GetPartition",\n"glue:GetPartitions",\n')),(0,r.kt)("p",null,"You will need these permissions on the glue databases you are writing to:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"glue:GetDatabase",\n"glue:GetDatabases",\n"glue:GetTable",\n"glue:GetTables",\n"glue:GetPartition",\n"glue:GetPartitions",\n"glue:BatchCreatePartition",\n"glue:BatchUpdatePartition",\n"glue:BatchDeletePartition",\n"glue:BatchDeleteTable",\n"glue:BatchDeleteTableVersion",\n"glue:CreatePartition",\n"glue:UpdatePartition",\n"glue:DeletePartition",\n"glue:CreateTable",\n"glue:UpdateTable",\n"glue:DeleteTable",\n"glue:DeleteTableVersion",\n')),(0,r.kt)("h2",{id:"s3-iam-permissions"},"S3 IAM permissions"),(0,r.kt)("p",null,"You will need these permissions on the S3 buckets that dbt-athena reads from:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"s3:GetObject",\n"s3:GetBucketLocation",\n"s3:ListBucket",\n"s3:ListBucketMultipartUploads",\n"s3:ListMultipartUploadParts",\n')),(0,r.kt)("p",null,"You will need these permissions on the S3 buckets you are writing to (buckets defined in ",(0,r.kt)("inlineCode",{parentName:"p"},"s3_staging_dir")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"s3_data_dir"),"):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"s3:GetObject",\n"s3:GetBucketLocation",\n"s3:ListBucket",\n"s3:ListBucketMultipartUploads",\n"s3:ListMultipartUploadParts",\n"s3:AbortMultipartUpload",\n"s3:PutObject",\n"s3:DeleteObject",\n')),(0,r.kt)("p",null,"If your buckets are encrypted using KMS, you will need these permissions on every KMS key of the buckets:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"kms:GenerateDataKey*",\n"kms:DescribeKey",\n"kms:Decrypt",\n')),(0,r.kt)("h2",{id:"lake-formation"},"Lake Formation"),(0,r.kt)("p",null,"If you are using databases managed by AWS Lake Formation, then you need to set these permissions on the role.:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'"lakeformation:GetDataAccess",\n')))}h.isMDXComponent=!0},2057:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"What is dbt-athena?",id:"introduction",sidebar_label:"Introduction",slug:"/"},l=void 0,d={unversionedId:"docs/introduction",id:"docs/introduction",title:"What is dbt-athena?",description:"dbt-athena is a community-owned adapter for dbt Core. The dbt-athena package contains all the code to enable dbt to work with AWS Athena and transform data using SQL.",source:"@site/docs/docs/introduction.md",sourceDirName:"docs",slug:"/",permalink:"/pr-preview/pr-5/",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/introduction.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"What is dbt-athena?",id:"introduction",sidebar_label:"Introduction",slug:"/"},sidebar:"docs",next:{title:"AWS resources",permalink:"/pr-preview/pr-5/docs/getting-started/prerequisites/aws-resources"}},p={},c=[{value:"Features of dbt-athena",id:"features-of-dbt-athena",level:2}],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"dbt-athena is a community-owned adapter for dbt Core. The dbt-athena package contains all the code to enable dbt to work with ",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/athena/"},"AWS Athena")," and transform data using SQL."),(0,r.kt)("p",null,"In essence, the dbt-athena adapter will transform existing data in Athena by leveraging the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/athena/latest/ug/create-table-as.html"},(0,r.kt)("inlineCode",{parentName:"a"},"CREATE TABLE AS"))," or ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/athena/latest/ug/create-view.html"},(0,r.kt)("inlineCode",{parentName:"a"},"CREATE VIEW"))," SQL queries in AWS Athena."),(0,r.kt)("h2",{id:"features-of-dbt-athena"},"Features of dbt-athena"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u2705 Supports dbt version ",(0,r.kt)("inlineCode",{parentName:"li"},"1.4.*")),(0,r.kt)("li",{parentName:"ul"},"\u2705 Supports ",(0,r.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/seeds"},"dbt seeds")),(0,r.kt)("li",{parentName:"ul"},"\u2705 Supports ",(0,r.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/build/snapshots"},"dbt snapshots")),(0,r.kt)("li",{parentName:"ul"},"\u2705 Supports ",(0,r.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/build/materializations#table"},"table materialization")," using Hive tables (Athena v2/v3) and ",(0,r.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html"},"Iceberg tables")," (Athena v3)"),(0,r.kt)("li",{parentName:"ul"},"\u2705 Supports ",(0,r.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/build/incremental-models"},"incremental models")," for Iceberg (",(0,r.kt)("inlineCode",{parentName:"li"},"merge")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"append"),") and Hive tables (",(0,r.kt)("inlineCode",{parentName:"li"},"insert_overwrite")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"append"),").")),(0,r.kt)("p",null,"Not supported yet: ",(0,r.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/build/python-models#configuring-python-models"},"Python models"),", ",(0,r.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/reference/resource-configs/persist_docs"},"persist docs")," for views."))}h.isMDXComponent=!0},7526:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Known issues",id:"known-issues"},l=void 0,d={unversionedId:"docs/known-issues",id:"docs/known-issues",title:"Known issues",description:"- Incremental Iceberg models: sync all columns on schema change can't remove columns used as partitioning. The only way, from a dbt perspective, is to do a full-refresh of the incremental model.",source:"@site/docs/docs/known-issues.md",sourceDirName:"docs",slug:"/docs/known-issues",permalink:"/pr-preview/pr-5/docs/known-issues",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/docs/known-issues.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Known issues",id:"known-issues"},sidebar:"docs",previous:{title:"Snapshots",permalink:"/pr-preview/pr-5/docs/configuration/snapshots"},next:{title:"Contributing",permalink:"/pr-preview/pr-5/docs/contributing/"}},p={},c=[],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Incremental Iceberg models: sync all columns on schema change can't remove columns used as partitioning. The only way, from a dbt perspective, is to do a full-refresh of the incremental model."),(0,r.kt)("li",{parentName:"ul"},"Tables, schemas and database should only be lowercase")))}h.isMDXComponent=!0},9252:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"How many dbt threads should I configure",id:"dbt-threads"},l=void 0,d={unversionedId:"faqs/Athena/dbt-threads",id:"faqs/Athena/dbt-threads",title:"How many dbt threads should I configure",description:"Athena has certain service API call quotas. The StartQueryExecution API supports 20 calls per second, and \u2013 if no api call is made in 4s \u2013 a burst to 80 calls. See the AWS Athena service limits documentation.",source:"@site/docs/faqs/Athena/dbt-threads.md",sourceDirName:"faqs/Athena",slug:"/faqs/Athena/dbt-threads",permalink:"/pr-preview/pr-5/faqs/Athena/dbt-threads",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/faqs/Athena/dbt-threads.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"How many dbt threads should I configure",id:"dbt-threads"},sidebar:"docs",previous:{title:"Frequently asked questions",permalink:"/pr-preview/pr-5/docs/faqs"},next:{title:"Athena limits Hive tables to 100 partitions",permalink:"/pr-preview/pr-5/faqs/Athena/too-many-open-partitions"}},p={},c=[],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Athena has certain service API call quotas. The ",(0,r.kt)("inlineCode",{parentName:"p"},"StartQueryExecution")," API supports 20 calls per second, and \u2013 if no api call is made in 4s \u2013 a burst to 80 calls. See the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/athena/latest/ug/service-limits.html#service-limits-api-calls"},"AWS Athena service limits documentation"),"."),(0,r.kt)("p",null,"Due to these limits, you should consider how many concurrent API requests are happening in your AWS account and configure your threads accordingly. A good average value for threads could be ",(0,r.kt)("inlineCode",{parentName:"p"},"threads: 8"),"."))}h.isMDXComponent=!0},9109:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>c});var n=a(7462),i=a(3366),r=(a(7294),a(3905)),o=["components"],s={title:"Athena limits Hive table to 100 partitions",sidebar_label:"Athena limits Hive tables to 100 partitions",id:"too-many-open-partitions"},l=void 0,d={unversionedId:"faqs/Athena/too-many-open-partitions",id:"faqs/Athena/too-many-open-partitions",title:"Athena limits Hive table to 100 partitions",description:"In some cases, you might experience HIVETOOMANYOPENPARTITIONS: Exceeded limit of 100 open writers for partitions/buckets.. Athena supports writing to 100 unique partition and bucket combinations per query. For example, if no buckets are defined in the destination table, you can specify a maximum of 100 partitions. If you specify five buckets, 20 partitions (each with five buckets) are allowed. If you exceed this count, an error occurs.",source:"@site/docs/faqs/Athena/too-many-open-partitions.md",sourceDirName:"faqs/Athena",slug:"/faqs/Athena/too-many-open-partitions",permalink:"/pr-preview/pr-5/faqs/Athena/too-many-open-partitions",draft:!1,editUrl:"https://github.com/dbt-athena/dbt-athena.github.io/edit/main/docs/faqs/Athena/too-many-open-partitions.md",tags:[],version:"current",lastUpdatedAt:1683060208,formattedLastUpdatedAt:"May 2, 2023",frontMatter:{title:"Athena limits Hive table to 100 partitions",sidebar_label:"Athena limits Hive tables to 100 partitions",id:"too-many-open-partitions"},sidebar:"docs",previous:{title:"How many dbt threads should I configure",permalink:"/pr-preview/pr-5/faqs/Athena/dbt-threads"}},p={},c=[],m={toc:c},u="wrapper";function h(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)(u,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"In some cases, you might experience ",(0,r.kt)("inlineCode",{parentName:"p"},"HIVE_TOO_MANY_OPEN_PARTITIONS: Exceeded limit of 100 open writers for partitions/buckets."),". Athena supports writing to 100 unique partition and bucket combinations per query. For example, if no buckets are defined in the destination table, you can specify a maximum of 100 partitions. If you specify five buckets, 20 partitions (each with five buckets) are allowed. If you exceed this count, an error occurs."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Iceberg tables are also affected by the same limitation. The ",(0,r.kt)("inlineCode",{parentName:"p"},"iceberg.max-partitions-per-writer")," setting in Trino is set by default to 100.")),(0,r.kt)("p",null,"AWS suggests a workaround in the documentation using ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/athena/latest/ug/ctas-insert-into.html"},"CTAs and INSERT INTO"),". We can automate this in dbt using a materialization. An example implementation \u2013 inspired by the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/dbt-labs/dbt-labs-experimental-features/tree/main/insert_by_period"},"Redshift insert_by_period materialization")," \u2013 can be found ",(0,r.kt)("a",{parentName:"p",href:"https://gist.github.com/jessedobbelaere/6fdb593f9e2cc732e9f142c56c9bac87"},"here"),"."))}h.isMDXComponent=!0}}]);